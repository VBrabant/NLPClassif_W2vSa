{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Embedding : Word 2 Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1 - Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File imported (14075 reviews)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('yelp_reviews_part1.json') as json_file:\n",
    "    reviews = json.load(json_file)\n",
    "\n",
    "print(\"File imported ({} reviews)\".format(len(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.2 - Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries and define helpful functions\n",
    "\n",
    "import re\n",
    "\n",
    "def cleaning(text) : \n",
    "    \"\"\" \n",
    "    Few operations to clean a text.\n",
    "    \"\"\"\n",
    "    chars_ = \"'*\"\n",
    "    chars = \"()\"\n",
    "\n",
    "    t = text.lower().replace(\"\\n\", \" \").replace(\"\\\"\", \"\")\n",
    "    for c in chars_ : \n",
    "        t = t.replace(c, \" \")\n",
    "    for c in chars : \n",
    "        t = t.replace(c, \"\")\n",
    "\n",
    "    t = \" \".join([w for w in t.split(\" \") if not w==\"\"])\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts cleaned and gathered : \n",
      "    'as someone who has worked with many museums, i was eager to visit this gallery on my most recent trip to las vegas. when i saw they would be showing infamous eggs of the house of faberge from the virginia museum of fine arts vmfa, i knew i had to go! tucked away near the gelateria and the garden, the gallery is pretty much hidden from view. it s what real estate agents would call cozy or charming - basically any euphemism for small. that being said, you can still see wonderful art at a gallery o...'\n"
     ]
    }
   ],
   "source": [
    "### Clean texts from every reviews and gather them\n",
    "\n",
    "keys = list(reviews.keys())\n",
    "\n",
    "texts = []\n",
    "for k in keys : \n",
    "    try : \n",
    "        text = reviews[k]['text']\n",
    "        t = cleaning(text)\n",
    "        texts.append(t)\n",
    "    except : None\n",
    "\n",
    "TEXT = \" \".join(texts)\n",
    "\n",
    "del reviews # free memory\n",
    "\n",
    "# verbose\n",
    "print(\"Texts cleaned and gathered : \\n    '\" + TEXT[:500] + \"...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30770 unique words.\n",
      "Let's count occurences and select only those who appears at least 20 times : \n",
      "    words done : 2500 (8%)\n",
      "    words done : 5000 (16%)\n",
      "    words done : 7500 (24%)\n",
      "    words done : 10000 (32%)\n",
      "    words done : 12500 (41%)\n",
      "    words done : 15000 (49%)\n",
      "    words done : 17500 (57%)\n",
      "    words done : 20000 (65%)\n",
      "    words done : 22500 (73%)\n",
      "    words done : 25000 (81%)\n",
      "    words done : 27500 (89%)\n",
      "    words done : 30000 (97%)\n",
      "We now have 4124 unique words\n",
      "File stored.\n"
     ]
    }
   ],
   "source": [
    "### Count words occurences and select \n",
    "\n",
    "occ = 20 # Minimal number of occurences for a word to be kept\n",
    "\n",
    "# create words list\n",
    "Words = re.findall(r\"[\\w']+\", TEXT)\n",
    "WordsSet = list(set(Words))\n",
    "N = len(WordsSet)\n",
    "\n",
    "# verbose\n",
    "print(str(N) + \" unique words.\") \n",
    "print(\"Let's count occurences and select only those who appears at least \" + str(occ) + \" times : \")\n",
    "\n",
    "# Count\n",
    "WordsCount = {}\n",
    "for i, w in enumerate(WordsSet) : \n",
    "    c = Words.count(w)\n",
    "    if c >= occ : # We keep words occuring at least \"occ\" times\n",
    "        WordsCount[w] = c\n",
    "    if (i+1)%2500 == 0 : print(\"    words done : \" + str(i+1) + \" (\" + str(round(100*(i+1)/N)) + \"%)\")\n",
    "\n",
    "numWords = len(WordsCount)\n",
    "        \n",
    "# verbose\n",
    "print(\"We now have {} unique words\".format(numWords))\n",
    "\n",
    "# Store file\n",
    "with open('wordscount.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(WordsCount, f, ensure_ascii=False, indent=4)   \n",
    "print(\"File stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### replace word by number \n",
    "\n",
    "WordsDict = {i:w for i, w in enumerate(list(WordsCount.keys()))}\n",
    "WordsDictReverse = {v:k for k, v in WordsDict.items()}\n",
    "Words = list(WordsCount.keys())\n",
    "\n",
    "del WordsCount # free memory\n",
    "\n",
    "# Store file\n",
    "with open('wordsDict.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(WordsDict, f, ensure_ascii=False, indent=4)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3 - W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries and define helpful functions\n",
    "\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def onehot(lst, N) : \n",
    "    \"\"\"\n",
    "    Compute one hot version of the input regarding a given size.\n",
    "    \"\"\"\n",
    "    return [1*(i in lst) for i in range(N)]\n",
    "\n",
    "def getData(batch) : \n",
    "    \"\"\"\n",
    "    From a batch, create well formated training elements.\n",
    "    \"\"\"\n",
    "    X = [t[0] for t in batch]\n",
    "    X_onehot = [onehot(x, N=numWords) for x in X]\n",
    "    X = torch.FloatTensor(X_onehot)\n",
    "    \n",
    "    Y = [t[1] for t in batch]\n",
    "    Y = torch.tensor(Y).reshape(-1)\n",
    "    \n",
    "    return X, Y   \n",
    "\n",
    "def getLoss(X, Y) :\n",
    "    \"\"\"\n",
    "    Compute loss.\n",
    "    \"\"\"\n",
    "    pred = model.forward(X)\n",
    "    output = loss(pred, Y)\n",
    "    return output\n",
    "\n",
    "def createBatches(dataSet, batch_size):\n",
    "    \"\"\"\n",
    "    Create batches regarding a given data set and a given batch size.\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    j=0\n",
    "    while len(dataSet) >  0: \n",
    "        batch = dataSet[:min(batch_size, len(dataSet)-1)]\n",
    "        dataSet = dataSet[min(batch_size, len(dataSet)-1):]\n",
    "        j += batch_size\n",
    "        \n",
    "        X, Y = getData(batch)\n",
    "        \n",
    "        batches.append([X, Y])\n",
    "        \n",
    "    return batches\n",
    "\n",
    "class MyW2V(nn.Module):\n",
    "    def __init__(self, num_words, hidden_size):\n",
    "        super(MyW2V, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_words, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_words)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training set (with window size of 9)...\n",
      "129051 phrases.\n",
      "    phrases processed : 10000 (8%)\n",
      "    phrases processed : 20000 (15%)\n",
      "    phrases processed : 30000 (23%)\n",
      "    phrases processed : 40000 (31%)\n",
      "    phrases processed : 50000 (39%)\n",
      "    phrases processed : 60000 (46%)\n",
      "    phrases processed : 70000 (54%)\n",
      "    phrases processed : 80000 (62%)\n",
      "    phrases processed : 90000 (70%)\n",
      "    phrases processed : 100000 (77%)\n",
      "    phrases processed : 110000 (85%)\n",
      "    phrases processed : 120000 (93%)\n",
      "Done. Set size : 1501675 elements\n"
     ]
    }
   ],
   "source": [
    "### Create Training set (CBOW style)\n",
    "\n",
    "windowRay = 4 # ray of window for the CBOW implementation\n",
    "\n",
    "phrases = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', TEXT)\n",
    "\n",
    "trainingSet = {}\n",
    "k = 0\n",
    "\n",
    "# verbose\n",
    "print(\"Creating training set (with window size of {})...\".format(2*windowRay+1))\n",
    "print(str(len(phrases)) + \" phrases.\")\n",
    "\n",
    "for i, phrase in enumerate(phrases) : \n",
    "    \n",
    "    # verbose\n",
    "    if (i+1)%10000==0 : print(\"    phrases processed : \" + str(i+1) + \" (\"+ str(round((i+1)/len(phrases)*100)) + \"%)\")\n",
    "    \n",
    "    # compute words list and clean them\n",
    "    words = re.findall(r\"[\\w']+\", phrase)\n",
    "    words = [w.lower().replace(\"'\", \" \") for w in words]\n",
    "\n",
    "    for j in range(len(words)):\n",
    "        y = words[j]\n",
    "        if y in Words : \n",
    "            m = max(j-windowRay, 0) # window min\n",
    "            M = min(j+windowRay+1, len(words)-1) # window max\n",
    "\n",
    "            x = words[m:j] + words[(j+1):M] \n",
    "\n",
    "            yn = WordsDictReverse[y]\n",
    "            xn = [WordsDictReverse[w] for w in x if w in Words] \n",
    "        \n",
    "        if len(xn) > 0 : trainingSet[k] = [xn, yn]\n",
    "        k += 1\n",
    "\n",
    "# Store TrainingSet\n",
    "with open('trainingset.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(trainingSet, f, ensure_ascii=False, indent=4)   \n",
    "\n",
    "del TEXT # Free Memory\n",
    "\n",
    "numWords = max([train[1] for train in list(trainingSet.values())]) + 1\n",
    "\n",
    "# verbose\n",
    "print(\"Done. Set size : {} elements\".format(len(trainingSet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of batches to compute : 23463\n",
      "    batches processed : 2000 (9%)\n",
      "    batches processed : 4000 (17%)\n",
      "    batches processed : 6000 (26%)\n",
      "    batches processed : 8000 (34%)\n",
      "    batches processed : 10000 (43%)\n",
      "    batches processed : 12000 (51%)\n",
      "    batches processed : 14000 (60%)\n",
      "    batches processed : 16000 (68%)\n",
      "    batches processed : 18000 (77%)\n",
      "    batches processed : 20000 (85%)\n",
      "    batches processed : 22000 (94%)\n"
     ]
    }
   ],
   "source": [
    "### Create batches ###\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# import training set\n",
    "with open('trainingset.json') as json_file:\n",
    "    trainingSet = json.load(json_file)\n",
    "        \n",
    "numWords = max([train[1] for train in list(trainingSet.values())]) + 1\n",
    "\n",
    "trainingSetList = list(trainingSet.values())\n",
    "del trainingSet # free memory\n",
    "lds = len(trainingSetList)\n",
    "\n",
    "bNum = int(lds/BATCH_SIZE)\n",
    "\n",
    "# verbose\n",
    "print(\"Estimation of batches (size {}) to compute : {}\".format(BATCH_SIZE, bNum))\n",
    "\n",
    "batches = []\n",
    "j = 0\n",
    "\n",
    "while len(trainingSetList) >  0: \n",
    "    batch = trainingSetList[:min(BATCH_SIZE, lds-1)]\n",
    "    trainingSetList = trainingSetList[min(BATCH_SIZE, lds-1):]\n",
    "\n",
    "    X, Y = getData(batch)\n",
    "\n",
    "    batches.append([X, Y])\n",
    "    \n",
    "    j += 1\n",
    "    \n",
    "    # verbose\n",
    "    if (j+1)%2000==0 : \n",
    "        print(\"    batches processed : {} ({}%)\".format(j+1, round((j+1)/bNum*100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating batches...\n",
      "    Session 1 on 10 done.\n",
      "    Session 2 on 10 done.\n",
      "    Session 3 on 10 done.\n",
      "    Session 4 on 10 done.\n",
      "    Session 5 on 10 done.\n"
     ]
    }
   ],
   "source": [
    "### Create batches ###\n",
    "\n",
    "BATCH_SESSION = 3 # subdivion of training set batches creation for computing performances\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "\n",
    "for bs in range(BATCH_SESSION) :\n",
    "    \n",
    "    \n",
    "    \n",
    "    # import training set\n",
    "    with open('trainingset.json') as json_file:\n",
    "        trainingSet = json.load(json_file)\n",
    "        \n",
    "    numWords = max([train[1] for train in list(trainingSet.values())]) + 1\n",
    "    \n",
    "    bsStep = int(np.ceil(len(trainingSet)/BATCH_SESSION))\n",
    "\n",
    "    trainingSetList = list(trainingSet.values())[max(0, bs*bsStep) : min((bs+1)*bsStep, len(trainingSet)-1)]\n",
    "    del trainingSet # free memory\n",
    "\n",
    "    trainingSet0 = random.sample(trainingSetList, len(trainingSetList))\n",
    "    del trainingSetList # free memory\n",
    "    batches.append(createBatches(trainingSet0, BATCH_SIZE))\n",
    "    del trainingSet0 # free memory\n",
    "    \n",
    "    # verbose\n",
    "    print(\"    Session {} on {} done.\".format(bs+1, BATCH_SESSION))\n",
    "    \n",
    "# verbose\n",
    "print(\"Batches created. Ready for training !...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training set\n",
    "with open('trainingset.json') as json_file:\n",
    "    trainingSet = json.load(json_file)\n",
    "        \n",
    "numWords = max([train[1] for train in list(trainingSet.values())]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create model\n",
    "\n",
    "NUM_WORDS = numWords\n",
    "NUM_HIDDEN = 128 # embedding dimension\n",
    "\n",
    "model = MyW2V(NUM_WORDS, NUM_HIDDEN)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 0/100. Loss : 8.3287 \n",
      "    Epoch 20/100. Loss : 4.483 \n",
      "    Epoch 40/100. Loss : 4.4558 \n",
      "    Epoch 60/100. Loss : 4.4331 \n",
      "    Epoch 80/100. Loss : 4.4178 \n",
      "    Epoch 100/100. Loss : 4.4195 \n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "### W2V TRAINING ###\n",
    "\n",
    "numEpochs = 100\n",
    "epoch = 0\n",
    "\n",
    "# create small set to see loss evolution\n",
    "testBatches = random.sample(batches, int(np.ceil(0.001*len(batches))))\n",
    "Xtest = []\n",
    "Ytest = []\n",
    "for batch in testBatches : \n",
    "    Xtest.append(batch[0])\n",
    "    Ytest.append(batch[1])\n",
    "\n",
    "Xtest = torch.cat(Xtest)\n",
    "Ytest = torch.cat(Ytest)\n",
    "\n",
    "totalLoss = float(getLoss(Xtest, Ytest)) # compute first loss\n",
    "\n",
    "# verbose\n",
    "print(\"Epoch 0/{}. Loss : {} \".format(numEpochs, round(totalLoss, ndigits=4)))\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "for epoch in range(numEpochs):\n",
    "\n",
    "    for batch in batches : \n",
    "\n",
    "        X, Y = batch\n",
    "        output = getLoss(X, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1)%20 == 0 : \n",
    "\n",
    "        totalLoss = float(getLoss(Xtest, Ytest))\n",
    "\n",
    "        print(\"Epoch {}/{}. Loss : {} \".format(epoch + 1, numEpochs, round(totalLoss, ndigits=4)))\n",
    "\n",
    "del batches # free memory\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>num</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>into</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.502643</td>\n",
       "      <td>-0.620104</td>\n",
       "      <td>0.944972</td>\n",
       "      <td>0.591801</td>\n",
       "      <td>0.761645</td>\n",
       "      <td>0.821589</td>\n",
       "      <td>0.088562</td>\n",
       "      <td>0.567810</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.635911</td>\n",
       "      <td>1.188772</td>\n",
       "      <td>-0.150391</td>\n",
       "      <td>0.097736</td>\n",
       "      <td>-0.032899</td>\n",
       "      <td>0.151074</td>\n",
       "      <td>-0.395667</td>\n",
       "      <td>0.155152</td>\n",
       "      <td>0.689732</td>\n",
       "      <td>0.998022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inside</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834079</td>\n",
       "      <td>-1.366196</td>\n",
       "      <td>1.580086</td>\n",
       "      <td>-0.108331</td>\n",
       "      <td>0.117351</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.295464</td>\n",
       "      <td>-0.496503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596483</td>\n",
       "      <td>-0.506305</td>\n",
       "      <td>-0.114696</td>\n",
       "      <td>-0.630845</td>\n",
       "      <td>-0.521578</td>\n",
       "      <td>-0.507318</td>\n",
       "      <td>0.413311</td>\n",
       "      <td>-0.065496</td>\n",
       "      <td>-0.093803</td>\n",
       "      <td>1.034184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>average</td>\n",
       "      <td>2</td>\n",
       "      <td>1.568417</td>\n",
       "      <td>-0.500123</td>\n",
       "      <td>1.767270</td>\n",
       "      <td>-1.470161</td>\n",
       "      <td>-1.665848</td>\n",
       "      <td>0.296147</td>\n",
       "      <td>-0.474358</td>\n",
       "      <td>-0.705745</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544593</td>\n",
       "      <td>0.016671</td>\n",
       "      <td>-0.890620</td>\n",
       "      <td>1.377905</td>\n",
       "      <td>-0.314022</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>-0.354492</td>\n",
       "      <td>-0.098363</td>\n",
       "      <td>-0.603086</td>\n",
       "      <td>-0.839770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fault</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.460616</td>\n",
       "      <td>-0.669066</td>\n",
       "      <td>0.285862</td>\n",
       "      <td>-0.583890</td>\n",
       "      <td>1.753119</td>\n",
       "      <td>2.132301</td>\n",
       "      <td>0.417271</td>\n",
       "      <td>-0.424196</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737542</td>\n",
       "      <td>-1.219218</td>\n",
       "      <td>-0.082606</td>\n",
       "      <td>0.134297</td>\n",
       "      <td>-2.251713</td>\n",
       "      <td>-0.389107</td>\n",
       "      <td>-2.228659</td>\n",
       "      <td>-0.873661</td>\n",
       "      <td>-1.090792</td>\n",
       "      <td>-0.292892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>current</td>\n",
       "      <td>4</td>\n",
       "      <td>0.905736</td>\n",
       "      <td>-1.178478</td>\n",
       "      <td>-1.380333</td>\n",
       "      <td>-2.760206</td>\n",
       "      <td>-0.523426</td>\n",
       "      <td>0.053070</td>\n",
       "      <td>-1.432050</td>\n",
       "      <td>-1.311643</td>\n",
       "      <td>...</td>\n",
       "      <td>3.140748</td>\n",
       "      <td>-1.272869</td>\n",
       "      <td>-0.224329</td>\n",
       "      <td>0.961605</td>\n",
       "      <td>1.213961</td>\n",
       "      <td>-0.966346</td>\n",
       "      <td>-1.467067</td>\n",
       "      <td>-0.590612</td>\n",
       "      <td>0.866681</td>\n",
       "      <td>0.382162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  num         0         1         2         3         4         5  \\\n",
       "0     into    0 -1.502643 -0.620104  0.944972  0.591801  0.761645  0.821589   \n",
       "1   inside    1  0.834079 -1.366196  1.580086 -0.108331  0.117351  0.545271   \n",
       "2  average    2  1.568417 -0.500123  1.767270 -1.470161 -1.665848  0.296147   \n",
       "3    fault    3 -0.460616 -0.669066  0.285862 -0.583890  1.753119  2.132301   \n",
       "4  current    4  0.905736 -1.178478 -1.380333 -2.760206 -0.523426  0.053070   \n",
       "\n",
       "          6         7  ...       118       119       120       121       122  \\\n",
       "0  0.088562  0.567810  ... -1.635911  1.188772 -0.150391  0.097736 -0.032899   \n",
       "1  0.295464 -0.496503  ... -0.596483 -0.506305 -0.114696 -0.630845 -0.521578   \n",
       "2 -0.474358 -0.705745  ... -0.544593  0.016671 -0.890620  1.377905 -0.314022   \n",
       "3  0.417271 -0.424196  ... -0.737542 -1.219218 -0.082606  0.134297 -2.251713   \n",
       "4 -1.432050 -1.311643  ...  3.140748 -1.272869 -0.224329  0.961605  1.213961   \n",
       "\n",
       "        123       124       125       126       127  \n",
       "0  0.151074 -0.395667  0.155152  0.689732  0.998022  \n",
       "1 -0.507318  0.413311 -0.065496 -0.093803  1.034184  \n",
       "2  0.013072 -0.354492 -0.098363 -0.603086 -0.839770  \n",
       "3 -0.389107 -2.228659 -0.873661 -1.090792 -0.292892  \n",
       "4 -0.966346 -1.467067 -0.590612  0.866681  0.382162  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Store w2v as csv\n",
    "\n",
    "df = pd.DataFrame({'word' : list(WordsDict.values()),\n",
    "                   'num' : list(WordsDict.keys())})\n",
    "df = pd.concat([df, pd.DataFrame(model.linear1.weight.data.numpy()).transpose()], axis=1)\n",
    "\n",
    "df.to_csv(\"myW2V.csv\", index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Classification : Encoder and Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File imported (14075 reviews)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "with open('yelp_reviews_part1.json') as json_file:\n",
    "    reviews = json.load(json_file)\n",
    "\n",
    "print(\"File imported ({} reviews)\".format(len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14075 reviews to prepare : \n",
      "    - 1000/14075\n",
      "    - 2000/14075\n",
      "    - 3000/14075\n",
      "    - 4000/14075\n",
      "    - 5000/14075\n",
      "    - 6000/14075\n",
      "    - 7000/14075\n",
      "    - 8000/14075\n",
      "    - 9000/14075\n",
      "    - 10000/14075\n",
      "    - 11000/14075\n",
      "    - 12000/14075\n",
      "    - 13000/14075\n",
      "    - 14000/14075\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Create dataSet\n",
    "\n",
    "wordsList = df['word'].tolist()\n",
    "\n",
    "dataSet = {}\n",
    "\n",
    "k = 0\n",
    "\n",
    "keys = list(reviews.keys())\n",
    "l = len(keys)\n",
    "\n",
    "# verbose\n",
    "print(\"{} reviews to prepare : \".format(l))\n",
    "\n",
    "for i, key in enumerate(keys) :\n",
    "    try :\n",
    "        text = reviews[key]['text']\n",
    "        words = re.findall(r\"[\\w']+\", text)\n",
    "        words = [w.lower().replace(\"'\", \" \") for w in words if w in wordsList]\n",
    "        tmp = df[df['word'].isin(words)]\n",
    "        vectors = [tmp[tmp['word'] == w].iloc[0,2:].tolist() for w in words]\n",
    "        \n",
    "        star = reviews[key]['stars']\n",
    "        \n",
    "        dataSet[k] = [vectors, star]\n",
    "        k += 1\n",
    "        \n",
    "        if (i+1)%1000 == 0 : \n",
    "            # verbose\n",
    "            print(\"    - {}/{}\".format(i+1, l))\n",
    "      \n",
    "    except : None\n",
    "\n",
    "print(\"Done.\")\n",
    "        \n",
    "del reviews # free memory    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size : 13371\n",
      "Test set size : 704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create training and test set\n",
    "\n",
    "splitRatio = 0.05 # ratio of data to test set\n",
    "\n",
    "dataSize = len(dataSet)\n",
    "indices = random.sample(range(dataSize), round(splitRatio*dataSize))\n",
    "\n",
    "keys = list(dataSet.keys())\n",
    "testSet = [dataSet[keys[i]] for i in indices]\n",
    "trainSet = [dataSet[keys[i]] for i in range(dataSize) if i not in indices]\n",
    "\n",
    "# verbose\n",
    "print(\"Training set size : {}\\nTest set size : {}\\n\".format(dataSize-len(indices), len(indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2 - Model : training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries and define helpful functions\n",
    "\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, h_dim, batch_first=True):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.lstm = nn.LSTM(input_dim, h_dim, batch_first=batch_first,\n",
    "                            bidirectional=True)\n",
    "\n",
    "    def init_hidden(self, b_size):\n",
    "        h0 = Variable(torch.zeros(1*2, b_size, self.h_dim))\n",
    "        c0 = Variable(torch.zeros(1*2, b_size, self.h_dim))\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden = self.init_hidden(x.size(0))\n",
    "        packed_emb = x\n",
    "\n",
    "        out, hidden = self.lstm(packed_emb, self.hidden)\n",
    "                \n",
    "        out = out[:, :, :self.h_dim] + out[:, :, self.h_dim:]\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, h_dim, n_head, attn_dim=16):\n",
    "        super(Attn, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.n_head = n_head\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(h_dim, attn_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(attn_dim, self.n_head)\n",
    "        )\n",
    "\n",
    "    def forward(self, encoder_outputs):\n",
    "        b_size = encoder_outputs.size(0)\n",
    "        attn_ene = self.main(encoder_outputs.view(-1, self.h_dim)) # (b, s, h) -> (b * s, n)\n",
    "        out =  F.softmax(attn_ene.view(b_size, -1), dim=1).unsqueeze(2) # (b*s, n) -> (b, s, n)\n",
    "        return attn_ene# out\n",
    "\n",
    "class AttnClassifier(nn.Module):\n",
    "    def __init__(self, h_dim, n_head, c_num, dropout=0.2):\n",
    "        super(AttnClassifier, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        self.attn = Attn(self.h_dim,self.n_head)\n",
    "        self.main = nn.Linear(self.h_dim * self.n_head, c_num)\n",
    "        \n",
    "    \n",
    "    def forward(self, encoder_outputs):\n",
    "        encoder_outputs = encoder_outputs.view(-1, self.h_dim, 1) #(b, h, 1)\n",
    "        \n",
    "        attns = self.attn(encoder_outputs) #(b, s, 1)\n",
    "        attns = attns.view(-1, 1, self.n_head) #(b, 1, n)\n",
    "        \n",
    "        feats = (encoder_outputs[0].view(-1, self.h_dim, 1) * attns).sum(dim=0) # (b, s, h) -> (b, h, n)\n",
    "        feats = feats.view(-1) #  (h*n)\n",
    "        #feats = self.dropout_layer(feats)\n",
    "        \n",
    "        output = self.main(feats)\n",
    "        return output, attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "### declare model\n",
    "\n",
    "encoder = EncoderRNN(128, 32)\n",
    "classifier = AttnClassifier(16, 3, 1)\n",
    "\n",
    "# optim\n",
    "optimizer = optim.Adam(chain(encoder.parameters(),classifier.parameters()), lr=0.0005)\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13371 reviews to train on.\n",
      "    Epoch 0/50 - Test/Training Manhattan error : 2.7/2.38\n",
      "    Epoch 5/50 - Test/Training Manhattan error : 0.48/0.46\n",
      "    Epoch 10/50 - Test/Training Manhattan error : 0.54/0.22\n",
      "    Epoch 15/50 - Test/Training Manhattan error : 0.58/0.3\n",
      "    Epoch 20/50 - Test/Training Manhattan error : 0.6/0.2\n",
      "    Epoch 25/50 - Test/Training Manhattan error : 0.68/0.14\n",
      "    Epoch 30/50 - Test/Training Manhattan error : 0.68/0.22\n",
      "    Epoch 35/50 - Test/Training Manhattan error : 0.7/0.04\n",
      "    Epoch 40/50 - Test/Training Manhattan error : 0.68/0.04\n",
      "    Epoch 45/50 - Test/Training Manhattan error : 0.76/0.06\n",
      "    Epoch 50/50 - Test/Training Manhattan error : 0.68/0.04\n",
      "Training done.\n"
     ]
    }
   ],
   "source": [
    "### Train model \n",
    "\n",
    "encoder.train()\n",
    "classifier.train()\n",
    "\n",
    "dataList = trainSet\n",
    "#del trainSet # free memory\n",
    "\n",
    "testSettmpVal = random.sample(testSet, min(50, len(testSet)))\n",
    "testSettmpTrain = random.sample(trainSet, min(50, len(trainSet)))\n",
    "\n",
    "\n",
    "# verbose\n",
    "print(\"{} reviews to train on.\".format(len(dataList)))\n",
    "\n",
    "numEpochs = 50\n",
    "\n",
    "# calculate error on validation set\n",
    "Y = []\n",
    "Ypred = []\n",
    "for test in testSettmpVal : \n",
    "    try :\n",
    "        Xtest = torch.Tensor(test[0])\n",
    "        Xtest = Xtest.view(1, -1, 128)\n",
    "        encoder_outputs = encoder(Xtest)\n",
    "        output, attn = classifier(encoder_outputs)\n",
    "        Ypred.append(float(output))\n",
    "        Y.append(test[1])\n",
    "    except : None\n",
    "\n",
    "errV = np.mean([abs(y-min(5, max(1, round(ypred)))) for y, ypred in zip(Y, Ypred)])\n",
    "\n",
    "# calculate error on training set\n",
    "Y = []\n",
    "Ypred = []\n",
    "for test in testSettmpTrain : \n",
    "    try :\n",
    "        Xtest = torch.Tensor(test[0])\n",
    "        Xtest = Xtest.view(1, -1, 128)\n",
    "        encoder_outputs = encoder(Xtest)\n",
    "        output, attn = classifier(encoder_outputs)\n",
    "        Ypred.append(float(output))\n",
    "        Y.append(test[1])\n",
    "    except : None\n",
    "\n",
    "errT = np.mean([abs(y-min(5, max(1, round(ypred)))) for y, ypred in zip(Y, Ypred)])\n",
    "\n",
    "# Verbose\n",
    "print(\"    Epoch 0/{} - Test/Training Manhattan error : {}/{}\".format(numEpochs, round(errV, ndigits=6), round(errT, ndigits=6)))\n",
    "\n",
    "for j in range(numEpochs) :\n",
    "    \n",
    "    # training\n",
    "    for i, data in enumerate(dataList):\n",
    "        x, y = data\n",
    "        if len(x)>0 : \n",
    "            x = torch.Tensor(x)\n",
    "            x = x.view(1, -1, 128)\n",
    "            y = torch.tensor(y).reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            encoder_outputs = encoder(x)\n",
    "            output, attn = classifier(encoder_outputs)\n",
    "            los = loss(output, y)\n",
    "            los.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if (j+1)%5==0 : \n",
    "        # calculate error on validation set\n",
    "        Y = []\n",
    "        Ypred = []\n",
    "        for test in testSettmpVal : \n",
    "            try :\n",
    "                Xtest = torch.Tensor(test[0])\n",
    "                Xtest = Xtest.view(1, -1, 128)\n",
    "                encoder_outputs = encoder(Xtest)\n",
    "                output, attn = classifier(encoder_outputs)\n",
    "                Ypred.append(float(output))\n",
    "                Y.append(test[1])\n",
    "            except : None\n",
    "\n",
    "        errV = np.mean([abs(y-min(5, max(1, round(ypred)))) for y, ypred in zip(Y, Ypred)])\n",
    "\n",
    "        # calculate error on training set\n",
    "        Y = []\n",
    "        Ypred = []\n",
    "        for test in testSettmpTrain : \n",
    "            try :\n",
    "                Xtest = torch.Tensor(test[0])\n",
    "                Xtest = Xtest.view(1, -1, 128)\n",
    "                encoder_outputs = encoder(Xtest)\n",
    "                output, attn = classifier(encoder_outputs)\n",
    "                Ypred.append(float(output))\n",
    "                Y.append(test[1])\n",
    "            except : None\n",
    "\n",
    "        errT = np.mean([abs(y-min(5, max(1, round(ypred)))) for y, ypred in zip(Y, Ypred)])\n",
    "\n",
    "        # Verbose\n",
    "        print(\"    Epoch {}/{} - Test/Training Manhattan error : {}/{}\".format(j+1, numEpochs, round(errV, ndigits=6), round(errT, ndigits=6)))\n",
    "\n",
    "\n",
    "# verbose\n",
    "print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3 - Model : test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute test\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "### compute test\n",
    "\n",
    "# verbose\n",
    "print(\"Compute test\")\n",
    "\n",
    "Y = []\n",
    "Ypred = []\n",
    "for test in testSet : \n",
    "    try :\n",
    "        Xtest = torch.Tensor(test[0])\n",
    "        Xtest = Xtest.view(1, -1, 128)\n",
    "        encoder_outputs = encoder(Xtest)\n",
    "        output, attn = classifier(encoder_outputs)\n",
    "        Ypred.append(float(output[0]))\n",
    "        #Ypred.append(torch.max(output, 1)[1][0].detach().numpy())\n",
    "        Y.append(test[1])\n",
    "    except : None\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Manhattan distance : 0.5767045454545454\n"
     ]
    }
   ],
   "source": [
    "### manhattan distance\n",
    "\n",
    "d = np.mean([abs(y-min(5, max(1, round(ypred)))) for y, ypred in zip(Y, Ypred)])\n",
    "\n",
    "# verbose\n",
    "print(\"Mean Manhattan distance : {}\".format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "\n",
      "Confusion matrix (row = pred/ col = true) : \n",
      "\n",
      "|    |   1 |   2 |   3 |   4 |   5 |\n",
      "|---:|----:|----:|----:|----:|----:|\n",
      "|  1 |  45 |   8 |   2 |   0 |   0 |\n",
      "|  2 |  34 |  10 |  13 |   1 |   2 |\n",
      "|  3 |  25 |  20 |  25 |  21 |  16 |\n",
      "|  4 |   4 |   4 |  34 |  81 |  91 |\n",
      "|  5 |   0 |   1 |   5 |  58 | 204 |\n",
      "\n",
      "\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "### compute confusion matrix \n",
    "\n",
    "Yval = list(set(Y))\n",
    "Yval.sort()\n",
    "\n",
    "confmat = []\n",
    "\n",
    "for y in Yval :\n",
    "    lst = [0, 0, 0, 0, 0]\n",
    "    for i in range(len(Y)) : \n",
    "        if Y[i] == y :\n",
    "            ypred = min(max(1, round(float(Ypred[i]))), 5)\n",
    "            lst[int(ypred-1)] += 1\n",
    "    confmat.append(lst)\n",
    "\n",
    "confmat = np.array(confmat).T\n",
    "df_cm = pd.DataFrame(confmat, columns = [1, 2, 3, 4, 5])\n",
    "df_cm.index = [1, 2, 3, 4, 5]\n",
    "\n",
    "tab = tabulate(df_cm, headers=[1, 2, 3, 4, 5], tablefmt=\"pipe\")\n",
    "\n",
    "# verbose\n",
    "print('=' * 89)\n",
    "print(\"\\nConfusion matrix (row = pred/ col = true) : \\n\")\n",
    "print(tab)\n",
    "print(\"\\n\")\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display results\n",
    "\n",
    "d = [y-min(5, max(1, round(ypred))) for y, ypred in zip(Y, Ypred)]\n",
    "d2 = {i:d.count(i) for i in range(-4, 5)}\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.bar(list(d2.keys()), list(d2.values()), color=['indianred']*4 + ['cornflowerblue'] + ['indianred']*4)\n",
    "plt.title(\"Distribution of differences between truth and predictions\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = [abs(y-min(5, max(1, round(ypred)))) for y, ypred in zip(Y, Ypred)]\n",
    "d2 = {i:d.count(i) for i in range(5)}\n",
    "d3 = {i:sum(list(d2.values())[:(i+1)])/sum(list(d2.values()))*100 for i in range(5)}\n",
    "\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(list(d3.keys()), list(d3.values()), 'g-o', color='cornflowerblue')\n",
    "plt.ylim(0, 110)\n",
    "plt.ylabel('%')\n",
    "plt.xticks([0, 1, 2, 3, 4])\n",
    "plt.xlabel('Absolute differences betwenn truth and predictions')\n",
    "plt.title(\"Cumulative success of predictions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III - Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\">{}</span>'.format(html_color, word)\n",
    "\n",
    "def mk_html(sentence, attns):\n",
    "    html = \"\"\n",
    "    for word, attn in zip(sentence, attns):\n",
    "        html += ' ' + highlight(\n",
    "            word,\n",
    "            attn\n",
    "        )\n",
    "    return html + \"<br><br>\\n\"\n",
    "\n",
    "def goodscale(lst) :\n",
    "    m = min(lst)\n",
    "    M = max(lst)\n",
    "    return [(x-m)**3/(M-m)**3 for x in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File imported (14075 reviews)\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "with open('yelp_reviews_part1.json') as json_file:\n",
    "    reviews = json.load(json_file)\n",
    "\n",
    "print(\"File imported ({} reviews)\".format(len(reviews)))\n",
    "\n",
    "keys = list(reviews.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute html output\n",
    "\n",
    "# choose data\n",
    "reviewKeys = []\n",
    "k = 0\n",
    "stars = []\n",
    "while len(reviewKeys) < 5 :\n",
    "    star = reviews[keys[k]]['stars']\n",
    "    if star not in stars and np.random.uniform() < 0.5 : \n",
    "        reviewKeys.append(keys[k])\n",
    "        stars.append(star)\n",
    "    k += 1\n",
    "\n",
    "f = open(\"attn.html\", \"w\") # store file\n",
    "r = 0\n",
    "for nr in reviewKeys : \n",
    "\n",
    "    # extract data\n",
    "    text = reviews[nr]['text']\n",
    "    star = reviews[nr]['stars']\n",
    "\n",
    "    # prepare text\n",
    "    wordsList = df['word'].tolist()\n",
    "\n",
    "    words = re.findall(r\"[\\w']+\", text)\n",
    "    words = [w.lower().replace(\"'\", \" \") for w in words if w in wordsList]\n",
    "    tmp = df[df['word'].isin(words)]\n",
    "    vectors = [tmp[tmp['word'] == w].iloc[0,2:].tolist() for w in words]\n",
    "\n",
    "    x = torch.tensor(vectors).view(1, -1, 128)\n",
    "    encoder_outputs = encoder(x)\n",
    "    output, attn = classifier(encoder_outputs)\n",
    "\n",
    "    # prediction\n",
    "    starpred = min(max(1, round(float(output))), 5)\n",
    "\n",
    "    # attentions\n",
    "    num_heads = attn.size()[2]\n",
    "    attentions = {i:[float(at[0][i]) for at in attn] for i in range(num_heads)}\n",
    "    for i in range(num_heads):\n",
    "        m = min([float(at[0][i]) for at in attn])\n",
    "        attentions[i] = [float(at[0][i]) for at in attn]\n",
    "        attentions[i] = goodscale(attentions[i])\n",
    "\n",
    "    # compute\n",
    "    wordsLst = []\n",
    "    wordsAttn = {i:[] for i in range(num_heads)}\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    w =  words[k]\n",
    "    l = len(w)\n",
    "    while i < len(text):\n",
    "        wt = text[i:(i+l)]\n",
    "        if wt.lower().replace(\"'\", \" \").replace(\"\\n\", \"\") == w : \n",
    "            wordsLst.append(text[j:i])\n",
    "            wordsLst.append(wt)\n",
    "            for nh in range(num_heads) :  \n",
    "                wordsAttn[nh].append(0)\n",
    "                wordsAttn[nh].append(attentions[nh][k])\n",
    "            i = i+l\n",
    "            j = i\n",
    "            k += 1\n",
    "            try : \n",
    "                w =  words[k]\n",
    "                l = len(w)\n",
    "            except : break\n",
    "        else :\n",
    "            i += 1\n",
    "\n",
    "    # Store data\n",
    "    f.write('<h3><center>Review {} on {}</center></h3> <b>Star prediction : {} - Truth : {} </b><br><br>'.format(r+1, 5, starpred, int(star)))\n",
    "    r+=1\n",
    "    for nh in range(num_heads) : \n",
    "        f.write('<i>Attention head {} </i><br>'.format(nh+1))\n",
    "        f.write( mk_html(wordsLst, wordsAttn[nh]))\n",
    "        \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
