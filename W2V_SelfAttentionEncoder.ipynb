{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file read\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "### Create datafile\n",
    "from zipfile import ZipFile \n",
    "import json\n",
    "\n",
    "file_name = \"yelp_academic_dataset_review.json.zip\"\n",
    "path = \"/Volumes/My Passport/Work/yelp_dataset/\"\n",
    "input_zip = ZipFile(path + file_name)\n",
    "del file_name\n",
    "\n",
    "name = input_zip.namelist()[0]\n",
    "data = input_zip.read(name)\n",
    "del name\n",
    "del input_zip\n",
    "\n",
    "print(\"file read\")\n",
    "\n",
    "n = int(len(data)*(0.17/100)) # we select 0.5% of dataset\n",
    "dat = data[:n]\n",
    "del data\n",
    "tmp = dat.decode(\"utf-8\")\n",
    "del dat\n",
    "tmp = tmp.split(\"}\\n{\")\n",
    "tmp[0] = tmp[0][1:]\n",
    "\n",
    "reviews = {}\n",
    "for i, r in enumerate(tmp) : \n",
    "    try : reviews[i] = json.loads(\"{\" + r + \"}\")\n",
    "    except : None\n",
    "del tmp\n",
    "# Store file\n",
    "with open('yelp_reviews_part1.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(reviews, f, ensure_ascii=False, indent=4)   \n",
    "    \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File imported (82211 reviews)\n"
     ]
    }
   ],
   "source": [
    "### Import (created) data\n",
    "import json\n",
    "\n",
    "with open('yelp_reviews_part1.json') as json_file:\n",
    "    reviews = json.load(json_file)\n",
    "\n",
    "print(\"File imported ({} reviews)\".format(len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(reviews.keys())\n",
    "key = keys[0]\n",
    "\n",
    "def cleaning(text) : \n",
    "    chars_ = \"'*\"\n",
    "    chars = \"()\"\n",
    "\n",
    "    t = text.lower().replace(\"\\n\", \" \").replace(\"\\\"\", \"\")\n",
    "    for c in chars_ : \n",
    "        t = t.replace(c, \" \")\n",
    "    for c in chars : \n",
    "        t = t.replace(c, \"\")\n",
    "\n",
    "    t = \" \".join([w for w in t.split(\" \") if not w==\"\"])\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for k in keys : \n",
    "    try : \n",
    "        text = reviews[k]['text']\n",
    "        t = cleaning(text)\n",
    "        texts.append(t)\n",
    "    except : None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as someone who has worked with many museums, i was eager to visit this gallery on my most recent trip to las vegas. when i saw they would be showing infamous eggs of the house of faberge from the virginia museum of fine arts vmfa, i knew i had to go! tucked away near the gelateria and the garden, the gallery is pretty much hidden from view. it s what real estate agents would call cozy or charming - basically any euphemism for small. that being said, you can still see wonderful art at a gallery of any size, so why the two s you ask? let me tell you: pricing for this, while relatively inexpensive for a las vegas attraction, is completely over the top. for the space and the amount of art you can fit in there, it is a bit much. it s not kid friendly at all. seriously, don t bring them. the security is not trained properly for the show. when the curating and design teams collaborate for exhibitions, there is a definite flow. that means visitors should view the art in a certain sequence, whe'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT = \" \".join(texts)\n",
    "del reviews # free memory\n",
    "TEXT[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70160 unique words.\n",
      "Let's count occurences and select only those who appears at least 10 times : \n",
      "    words done : 2500 (4%)\n",
      "    words done : 5000 (7%)\n",
      "    words done : 7500 (11%)\n",
      "    words done : 10000 (14%)\n",
      "    words done : 12500 (18%)\n",
      "    words done : 15000 (21%)\n",
      "    words done : 17500 (25%)\n",
      "    words done : 20000 (29%)\n",
      "    words done : 22500 (32%)\n",
      "    words done : 25000 (36%)\n",
      "    words done : 27500 (39%)\n",
      "    words done : 30000 (43%)\n",
      "    words done : 32500 (46%)\n",
      "    words done : 35000 (50%)\n",
      "    words done : 37500 (53%)\n",
      "    words done : 40000 (57%)\n",
      "    words done : 42500 (61%)\n",
      "    words done : 45000 (64%)\n",
      "    words done : 47500 (68%)\n",
      "    words done : 50000 (71%)\n",
      "    words done : 52500 (75%)\n",
      "    words done : 55000 (78%)\n",
      "    words done : 57500 (82%)\n",
      "    words done : 60000 (86%)\n",
      "    words done : 62500 (89%)\n",
      "    words done : 65000 (93%)\n",
      "    words done : 67500 (96%)\n",
      "    words done : 70000 (100%)\n",
      "We now have 16014 unique words\n",
      "File stored.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "occ = 10\n",
    "\n",
    "Words = re.findall(r\"[\\w']+\", TEXT)\n",
    "WordsSet = list(set(Words))\n",
    "N = len(WordsSet)\n",
    "\n",
    "# verbose\n",
    "print(str(N) + \" unique words.\") \n",
    "print(\"Let's count occurences and select only those who appears at least \" + str(occ) + \" times : \")\n",
    "\n",
    "WordsCount = {}\n",
    "for i, w in enumerate(WordsSet) : \n",
    "    c = Words.count(w)\n",
    "    if c >= occ : # We keep words occuring at least \"occ\" times\n",
    "        WordsCount[w] = c\n",
    "    if (i+1)%2500 == 0 : print(\"    words done : \" + str(i+1) + \" (\" + str(round(100*(i+1)/N)) + \"%)\")\n",
    "\n",
    "numWords = len(WordsCount)\n",
    "        \n",
    "# verbose\n",
    "print(\"We now have {} unique words\".format(numWords))\n",
    "\n",
    "# Store file\n",
    "with open('wordscount.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(WordsCount, f, ensure_ascii=False, indent=4)   \n",
    "print(\"File stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (20, 5))\n",
    "plt.hist(WordsCount.values(), range=[occ,200], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace word by number\n",
    "WordsDict = {i:w for i, w in enumerate(list(WordsCount.keys()))}\n",
    "WordsDictReverse = {v:k for k, v in WordsDict.items()}\n",
    "Words = list(WordsCount.keys())\n",
    "\n",
    "del WordsCount # free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyW2V(nn.Module):\n",
    "    def __init__(self, num_words, hidden_size):\n",
    "        super(MyW2V, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(num_words, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_words)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowRay = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training set (with window size of 11)...\n",
      "761332 phrases.\n",
      "    phrases processed : 10000 (1%)\n",
      "    phrases processed : 20000 (3%)\n",
      "    phrases processed : 30000 (4%)\n",
      "    phrases processed : 40000 (5%)\n",
      "    phrases processed : 50000 (7%)\n",
      "    phrases processed : 60000 (8%)\n",
      "    phrases processed : 70000 (9%)\n",
      "    phrases processed : 80000 (11%)\n",
      "    phrases processed : 90000 (12%)\n",
      "    phrases processed : 100000 (13%)\n",
      "    phrases processed : 110000 (14%)\n",
      "    phrases processed : 120000 (16%)\n",
      "    phrases processed : 130000 (17%)\n",
      "    phrases processed : 140000 (18%)\n",
      "    phrases processed : 150000 (20%)\n",
      "    phrases processed : 160000 (21%)\n",
      "    phrases processed : 170000 (22%)\n",
      "    phrases processed : 180000 (24%)\n",
      "    phrases processed : 190000 (25%)\n",
      "    phrases processed : 200000 (26%)\n",
      "    phrases processed : 210000 (28%)\n",
      "    phrases processed : 220000 (29%)\n",
      "    phrases processed : 230000 (30%)\n",
      "    phrases processed : 240000 (32%)\n",
      "    phrases processed : 250000 (33%)\n",
      "    phrases processed : 260000 (34%)\n",
      "    phrases processed : 270000 (35%)\n",
      "    phrases processed : 280000 (37%)\n",
      "    phrases processed : 290000 (38%)\n",
      "    phrases processed : 300000 (39%)\n",
      "    phrases processed : 310000 (41%)\n",
      "    phrases processed : 320000 (42%)\n",
      "    phrases processed : 330000 (43%)\n",
      "    phrases processed : 340000 (45%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b56b4be4902d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0myn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordsDictReverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mWordsDictReverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrainingSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b56b4be4902d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0myn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordsDictReverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mxn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mWordsDictReverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mWords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrainingSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "phrases = re.split(r' *[\\.\\?!][\\'\"\\)\\]]* *', TEXT)\n",
    "trainingSet = {}\n",
    "k = 0\n",
    "\n",
    "# verbose\n",
    "print(\"Creating training set (with window size of {})...\".format(2*windowRay+1))\n",
    "print(str(len(phrases)) + \" phrases.\")\n",
    "\n",
    "for i, phrase in enumerate(phrases) : \n",
    "    \n",
    "    # verbose\n",
    "    if (i+1)%10000==0 : print(\"    phrases processed : \" + str(i+1) + \" (\"+ str(round((i+1)/len(phrases)*100)) + \"%)\")\n",
    "    \n",
    "    words = re.findall(r\"[\\w']+\", phrase)\n",
    "    words = [w.lower().replace(\"'\", \" \") for w in words]\n",
    "\n",
    "    for j in range(len(words)):\n",
    "        y = words[j]\n",
    "        if y in Words : \n",
    "            m = max(j-windowRay, 0)\n",
    "            M = min(j+windowRay+1, len(words)-1)\n",
    "\n",
    "            x = words[m:j] + words[(j+1):M]\n",
    "\n",
    "            yn = WordsDictReverse[y]\n",
    "            xn = [WordsDictReverse[w] for w in x if w in Words] \n",
    "\n",
    "        trainingSet[k] = [xn, yn]\n",
    "        k += 1\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store TrainingSet\n",
    "with open('trainingset.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(trainingSet, f, ensure_ascii=False, indent=4)   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del TEXT # Free Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import training set\n",
    "import json\n",
    "\n",
    "with open('trainingset.json') as json_file:\n",
    "    trainingSet = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(lst, N) : \n",
    "    return [1*(i in lst) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS = numWords\n",
    "NUM_HIDDEN = 128\n",
    "\n",
    "model = MyW2V(NUM_WORDS, NUM_HIDDEN)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(batch) : \n",
    "    X = [t[0] for t in batch]\n",
    "    X_onehot = [onehot(x, N=numWords) for x in X]\n",
    "    X = torch.FloatTensor(X_onehot)\n",
    "    \n",
    "    Y = [t[1] for t in batch]\n",
    "    Y = torch.tensor(Y).reshape(-1)\n",
    "    \n",
    "    return X, Y   \n",
    "\n",
    "def getLoss(X, Y):\n",
    "    pred = model.forward(X)\n",
    "    output = loss(pred, Y)\n",
    "    return output\n",
    "\n",
    "def createBatches(dataSet, batch_size):\n",
    "    batches = []\n",
    "    j=0\n",
    "    while j < len(dataSet) : \n",
    "        batch = dataSet[j:min(j+BATCH_SIZE, len(dataSet)-1)]\n",
    "        j += BATCH_SIZE\n",
    "        \n",
    "        X, Y = getData(batch)\n",
    "        \n",
    "        batches.append([X, Y])\n",
    "        \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : \n",
      "    - Loss : 8.8706\n",
      "Batches created. Duration : 8 min.\n",
      "Epoch 10 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 3.8953\n",
      "    - Duration : 2 min.\n",
      "Epoch 20 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 3.2776\n",
      "    - Duration : 2 min.\n",
      "Epoch 30 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 3.0122\n",
      "    - Duration : 2 min.\n",
      "Epoch 40 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 2.8775\n",
      "    - Duration : 2 min.\n",
      "Epoch 50 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 2.7984\n",
      "    - Duration : 2 min.\n",
      "Epoch 60 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 2.7467\n",
      "    - Duration : 2 min.\n",
      "Epoch 70 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 2.7099\n",
      "    - Duration : 2 min.\n",
      "Epoch 80 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 2.6822\n",
      "    - Duration : 2 min.\n",
      "Epoch 90 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 2.6608\n",
      "    - Duration : 2 min.\n",
      "Epoch 100 : \n",
      "    - Batch size : 64\n",
      "    - Loss : 2.644\n",
      "    - Duration : 2 min.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "trainingSetList = list(trainingSet.values())\n",
    "del trainingSet # free memory\n",
    "\n",
    "testSet = random.sample(trainingSetList, round(0.01*len(trainingSetList)))\n",
    "Xtest, Ytest = getData(testSet)\n",
    "\n",
    "totalLoss = float(getLoss(Xtest, Ytest))\n",
    "# verbose\n",
    "print(\"Epoch 0 : \")\n",
    "print(\"    - Loss : \" + str(round(totalLoss, ndigits=4)))\n",
    "\n",
    "epoch = 0\n",
    "\n",
    "trainingSet0 = random.sample(trainingSetList, len(trainingSetList))\n",
    "del trainingSetList # free memory\n",
    "t1 = datetime.now()\n",
    "batches = createBatches(trainingSet0, BATCH_SIZE)\n",
    "del trainingSet0 # free memory\n",
    "t2 = datetime.now()  - t1\n",
    "duration = t2.seconds // 60\n",
    "\n",
    "# verbose\n",
    "print(\"Batches created. Duration : \" + str(duration) + \" min.\")\n",
    "    \n",
    "for _ in range(100):\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "    t1 = datetime.now()\n",
    "    \n",
    "    #batches = random.sample(batches, len(batches))\n",
    "    \n",
    "    for batch in batches : \n",
    "\n",
    "        X, Y = batch\n",
    "        output = getLoss(X, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    t2 = datetime.now()  - t1\n",
    "    duration = t2.seconds // 60\n",
    "    \n",
    "    if epoch%10 == 0 : \n",
    "    \n",
    "        totalLoss = float(getLoss(Xtest, Ytest))\n",
    "\n",
    "        print(\"Epoch \" + str(epoch) + \" : \")\n",
    "        print(\"    - Batch size : \" + str(BATCH_SIZE))\n",
    "        print(\"    - Loss : \" + str(round(totalLoss, ndigits=4)))\n",
    "        print(\"    - Duration : \" + str(duration) + \" min.\")\n",
    "        \n",
    "del batches # free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'word' : list(WordsDict.values()),\n",
    "                   'num' : list(WordsDict.keys())})\n",
    "df = pd.concat([df, pd.DataFrame(model.linear1.weight.data.numpy()).transpose()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>num</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corned</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>-0.302686</td>\n",
       "      <td>0.716478</td>\n",
       "      <td>1.760051</td>\n",
       "      <td>1.166899</td>\n",
       "      <td>-0.153824</td>\n",
       "      <td>-0.940575</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.487021</td>\n",
       "      <td>-0.555046</td>\n",
       "      <td>0.254399</td>\n",
       "      <td>-1.070017</td>\n",
       "      <td>1.447841</td>\n",
       "      <td>1.340765</td>\n",
       "      <td>0.318240</td>\n",
       "      <td>0.876247</td>\n",
       "      <td>1.235983</td>\n",
       "      <td>-0.705773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>garlicky</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.576522</td>\n",
       "      <td>-1.323343</td>\n",
       "      <td>-0.641931</td>\n",
       "      <td>-1.068634</td>\n",
       "      <td>0.611991</td>\n",
       "      <td>0.391321</td>\n",
       "      <td>-0.758668</td>\n",
       "      <td>-0.857353</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.106937</td>\n",
       "      <td>-1.164347</td>\n",
       "      <td>0.279036</td>\n",
       "      <td>-0.430467</td>\n",
       "      <td>1.378840</td>\n",
       "      <td>2.385134</td>\n",
       "      <td>-1.398105</td>\n",
       "      <td>0.982056</td>\n",
       "      <td>-1.549440</td>\n",
       "      <td>0.026775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>german</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769606</td>\n",
       "      <td>-0.875350</td>\n",
       "      <td>0.073682</td>\n",
       "      <td>-0.019873</td>\n",
       "      <td>1.460747</td>\n",
       "      <td>-0.061882</td>\n",
       "      <td>0.209817</td>\n",
       "      <td>-0.827818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377502</td>\n",
       "      <td>-0.344845</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-1.617766</td>\n",
       "      <td>0.175091</td>\n",
       "      <td>0.661808</td>\n",
       "      <td>0.682916</td>\n",
       "      <td>-0.005390</td>\n",
       "      <td>-0.584258</td>\n",
       "      <td>0.335614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eight</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.364568</td>\n",
       "      <td>-0.257157</td>\n",
       "      <td>0.036172</td>\n",
       "      <td>-0.305355</td>\n",
       "      <td>0.437882</td>\n",
       "      <td>-1.602795</td>\n",
       "      <td>-0.654901</td>\n",
       "      <td>0.845419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370201</td>\n",
       "      <td>-0.063870</td>\n",
       "      <td>-0.641261</td>\n",
       "      <td>-1.762030</td>\n",
       "      <td>1.441150</td>\n",
       "      <td>-1.061864</td>\n",
       "      <td>1.663599</td>\n",
       "      <td>0.093128</td>\n",
       "      <td>-0.495082</td>\n",
       "      <td>1.556980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shown</td>\n",
       "      <td>4</td>\n",
       "      <td>1.159035</td>\n",
       "      <td>-2.261499</td>\n",
       "      <td>0.972445</td>\n",
       "      <td>-0.082260</td>\n",
       "      <td>1.013518</td>\n",
       "      <td>0.301240</td>\n",
       "      <td>-0.781852</td>\n",
       "      <td>-1.491687</td>\n",
       "      <td>...</td>\n",
       "      <td>1.549682</td>\n",
       "      <td>-1.033483</td>\n",
       "      <td>0.910200</td>\n",
       "      <td>-1.549716</td>\n",
       "      <td>1.810117</td>\n",
       "      <td>-1.269402</td>\n",
       "      <td>-1.289852</td>\n",
       "      <td>-0.600029</td>\n",
       "      <td>-1.090389</td>\n",
       "      <td>0.454459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  num         0         1         2         3         4         5  \\\n",
       "0    corned    0  0.026023 -0.302686  0.716478  1.760051  1.166899 -0.153824   \n",
       "1  garlicky    1 -1.576522 -1.323343 -0.641931 -1.068634  0.611991  0.391321   \n",
       "2    german    2  0.769606 -0.875350  0.073682 -0.019873  1.460747 -0.061882   \n",
       "3     eight    3 -0.364568 -0.257157  0.036172 -0.305355  0.437882 -1.602795   \n",
       "4     shown    4  1.159035 -2.261499  0.972445 -0.082260  1.013518  0.301240   \n",
       "\n",
       "          6         7  ...       118       119       120       121       122  \\\n",
       "0 -0.940575  0.027834  ... -0.487021 -0.555046  0.254399 -1.070017  1.447841   \n",
       "1 -0.758668 -0.857353  ... -1.106937 -1.164347  0.279036 -0.430467  1.378840   \n",
       "2  0.209817 -0.827818  ...  0.377502 -0.344845  0.583333 -1.617766  0.175091   \n",
       "3 -0.654901  0.845419  ...  0.370201 -0.063870 -0.641261 -1.762030  1.441150   \n",
       "4 -0.781852 -1.491687  ...  1.549682 -1.033483  0.910200 -1.549716  1.810117   \n",
       "\n",
       "        123       124       125       126       127  \n",
       "0  1.340765  0.318240  0.876247  1.235983 -0.705773  \n",
       "1  2.385134 -1.398105  0.982056 -1.549440  0.026775  \n",
       "2  0.661808  0.682916 -0.005390 -0.584258  0.335614  \n",
       "3 -1.061864  1.663599  0.093128 -0.495082  1.556980  \n",
       "4 -1.269402 -1.289852 -0.600029 -1.090389  0.454459  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"myW2V.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz = df.sample(20)\n",
    "df_viz.head()\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "# dim reduc : ACP\n",
    "X = df_viz.iloc[:,2:].values\n",
    "\n",
    "pca = decomposition.PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "X = pca.transform(X)\n",
    "\n",
    "n = len(X)\n",
    "X1 = [X[i][0] for i in range(n)]\n",
    "X2 = [X[i][1] for i in range(n)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explained information : 19%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "words = df_viz.iloc[:,0].values\n",
    "\n",
    "print(\"\\nExplained information : \" + str(int(100*sum(pca.explained_variance_ratio_))) + \"%\\n\")\n",
    "\n",
    "fig = plt.figure(figsize=(17, 7))\n",
    "plt.axis([min(X1)*1.1, max(X1)*1.1, min(X2)*1.1, max(X2)*1.1])\n",
    "for w, x, y in zip(words, X1, X2):\n",
    "    plt.text(x, y, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File imported (4102 reviews)\n"
     ]
    }
   ],
   "source": [
    "### prepare dataset\n",
    "\n",
    "# Import (created) data\n",
    "import json\n",
    "\n",
    "with open('yelp_reviews_part1.json') as json_file:\n",
    "    reviews = json.load(json_file)\n",
    "\n",
    "print(\"File imported ({} reviews)\".format(len(reviews)))\n",
    "\n",
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "wordsList = df['word'].tolist()\n",
    "\n",
    "dataSet = {}\n",
    "k = 0\n",
    "\n",
    "keys = list(reviews.keys())\n",
    "for key in keys :\n",
    "    try :\n",
    "        text = reviews[key]['text']\n",
    "        words = re.findall(r\"[\\w']+\", text)\n",
    "        words = [w.lower().replace(\"'\", \" \") for w in words if w in wordsList]\n",
    "        tmp = df[df['word'].isin(words)]\n",
    "        vectors = [tmp[tmp['word'] == w].iloc[0,2:].tolist() for w in words]\n",
    "        \n",
    "        star = reviews[key]['stars']\n",
    "        \n",
    "        dataSet[k] = [vectors, star]\n",
    "        k += 1\n",
    "      \n",
    "    except : None\n",
    "\n",
    "print(\"DONE\")\n",
    "        \n",
    "del reviews # free memory    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stars = [dataSet[k][1] for k in list(dataSet.keys())]\n",
    "plt.hist(stars, align='mid', bins=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size : 3897\n",
      "Test set size : 205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splitRatio = 0.05\n",
    "\n",
    "dataSize = len(dataSet)\n",
    "indices = random.sample(range(dataSize), round(splitRatio*dataSize))\n",
    "\n",
    "keys = list(dataSet.keys())\n",
    "testSet = [dataSet[keys[i]] for i in indices]\n",
    "trainSet = [dataSet[keys[i]] for i in range(dataSize) if i not in indices]\n",
    "\n",
    "# verbose\n",
    "print(\"Training set size : {}\\nTest set size : {}\\n\".format(dataSize-len(indices), len(indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_dim, h_dim, batch_first=True):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.lstm = nn.LSTM(input_dim, h_dim, batch_first=batch_first,\n",
    "                            bidirectional=True)\n",
    "\n",
    "    def init_hidden(self, b_size):\n",
    "        h0 = Variable(torch.zeros(1*2, b_size, self.h_dim))\n",
    "        c0 = Variable(torch.zeros(1*2, b_size, self.h_dim))\n",
    "        return (h0, c0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden = self.init_hidden(x.size(0))\n",
    "        packed_emb = x\n",
    "\n",
    "        out, hidden = self.lstm(packed_emb, self.hidden)\n",
    "                \n",
    "        out = out[:, :, :self.h_dim] + out[:, :, self.h_dim:]\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, h_dim):\n",
    "        super(Attn, self).__init__()\n",
    "        self.h_dim = h_dim\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(h_dim, 24),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(24,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, encoder_outputs):\n",
    "        b_size = encoder_outputs.size(0)\n",
    "        attn_ene = self.main(encoder_outputs.view(-1, self.h_dim)) # (b, s, h) -> (b * s, 1)\n",
    "        return F.softmax(attn_ene.view(b_size, -1), dim=1).unsqueeze(2) # (b*s, 1) -> (b, s, 1)\n",
    "\n",
    "class AttnClassifier(nn.Module):\n",
    "    def __init__(self, h_dim, c_num):\n",
    "        super(AttnClassifier, self).__init__()\n",
    "        self.attn = Attn(h_dim)\n",
    "        self.main = nn.Linear(h_dim, c_num)\n",
    "        \n",
    "    \n",
    "    def forward(self, encoder_outputs):\n",
    "        attns = self.attn(encoder_outputs) #(b, s, 1)\n",
    "        feats = (encoder_outputs * attns).sum(dim=1) # (b, s, h) -> (b, h)\n",
    "        #output = F.softmax(self.main(feats))\n",
    "        output = self.main(feats)\n",
    "        return output, attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model\n",
    "encoder = EncoderRNN(128, 32)\n",
    "classifier = AttnClassifier(32, 1)\n",
    "\n",
    "# optim\n",
    "optimizer = optim.Adam(chain(encoder.parameters(),classifier.parameters()), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "#loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3897 reviews to train on.\n",
      "    10 epochs done. Error : 0.702439\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-547-2728901532de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-544-a7bf4f388ba1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpacked_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 570\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encoder.train()\n",
    "classifier.train()\n",
    "correct = 0\n",
    "dataList = trainSet\n",
    "print(str(len(dataList)) + \" reviews to train on.\")\n",
    "for j in range(50) :\n",
    "    for i, data in enumerate(dataList):\n",
    "        x, y = data\n",
    "        if len(x)>0 : \n",
    "            x = torch.Tensor(x)\n",
    "            x = x.view(1, -1, 128)\n",
    "            #y = torch.tensor(y-1).reshape(-1).type(torch.LongTensor)\n",
    "            y = torch.tensor(y).reshape(-1)\n",
    "            optimizer.zero_grad()\n",
    "            encoder_outputs = encoder(x)\n",
    "            output, attn = classifier(encoder_outputs)\n",
    "            los = loss(output, y)\n",
    "            los.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if (j+1)%10==0 : \n",
    "        # calculate error on test set\n",
    "        Y = []\n",
    "        Ypred = []\n",
    "        for test in testSet : \n",
    "            try :\n",
    "                Xtest = torch.Tensor(test[0])\n",
    "                Xtest = Xtest.view(1, -1, 128)\n",
    "                encoder_outputs = encoder(Xtest)\n",
    "                output, attn = classifier(encoder_outputs)\n",
    "                Ypred.append(output[0][0].detach().numpy())\n",
    "                Y.append(test[1])\n",
    "            except : None\n",
    "        \n",
    "        err = np.mean([abs(y-min(5, max(1, round(float(ypred))))) for y, ypred in zip(Y, Ypred)])\n",
    "        \n",
    "        # Verbose\n",
    "        print(\"    {} epochs done. Error : {}\".format(j+1, round(err, ndigits=6)))\n",
    "\n",
    "# verbose\n",
    "print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test phase\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"test phase\")\n",
    "\n",
    "Y = []\n",
    "Ypred = []\n",
    "for test in testSet : \n",
    "    try :\n",
    "        Xtest = torch.Tensor(test[0])\n",
    "        Xtest = Xtest.view(1, -1, 128)\n",
    "        encoder_outputs = encoder(Xtest)\n",
    "        output, attn = classifier(encoder_outputs)\n",
    "        Ypred.append(output[0][0].detach().numpy())\n",
    "        #Ypred.append(torch.max(output, 1)[1][0].detach().numpy())\n",
    "        Y.append(test[1])\n",
    "    except : None\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6487804878048781"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([abs(y-round(float(ypred))) for y, ypred in zip(Y, Ypred)])\n",
    "#np.mean([abs(y-ypred) for y, ypred in zip(Y, Ypred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yval = list(set(Y))\n",
    "Yval.sort()\n",
    "\n",
    "confmat = []\n",
    "\n",
    "for y in Yval :\n",
    "    lst = [0, 0, 0, 0, 0]\n",
    "    for i in range(len(Y)) : \n",
    "        if Y[i] == y :\n",
    "            ypred = min(max(1, round(float(Ypred[i]))), 5)\n",
    "            lst[int(ypred-1)] += 1\n",
    "    confmat.append(lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  4,  1,  0,  3],\n",
       "       [10,  7,  5,  2,  2],\n",
       "       [ 5,  3,  5,  9,  4],\n",
       "       [ 3,  0,  7, 24, 20],\n",
       "       [ 0,  1,  2, 17, 59]])"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(confmat).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.19512195121951"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([confmat[i][i] for i in range(5)])/len(Y)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat2 = confmat\n",
    "for i in range(5):\n",
    "    for j  in range(5) : \n",
    "        confmat2[i][j] = round(confmat[i][j]/len(Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  2,  0,  0,  1],\n",
       "       [ 5,  3,  2,  1,  1],\n",
       "       [ 2,  1,  2,  4,  2],\n",
       "       [ 1,  0,  3, 12, 10],\n",
       "       [ 0,  0,  1,  8, 29]])"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(confmat2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vizualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-463-e34aa7e5df0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mXtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mXtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6"
     ]
    }
   ],
   "source": [
    "test = testSet[6]\n",
    "Xtest = torch.Tensor(test[0])\n",
    "Xtest = Xtest.view(1, -1, 128)\n",
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1325]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs = encoder(Xtest)\n",
    "output, attn = classifier(encoder_outputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4873e-02, 2.5949e-03, 2.1146e-04, 3.4034e-04, 1.7443e-02, 4.3202e-01,\n",
       "        1.2596e-03, 8.5964e-04, 2.1628e-01, 4.4622e-05, 9.9330e-03, 2.9967e-05,\n",
       "        1.4599e-06, 2.6095e-05, 5.5018e-04, 3.2486e-02, 8.0658e-06, 2.7958e-03,\n",
       "        2.1654e-06, 1.0675e-07, 1.0591e-07, 6.0541e-08, 1.3530e-05, 2.0220e-09,\n",
       "        5.7851e-11, 2.9865e-09, 1.1099e-03, 1.3531e-02, 1.4685e-05, 2.0168e-05,\n",
       "        1.5390e-08, 2.9074e-03, 3.1314e-08, 3.9030e-03, 1.0896e-04, 8.3598e-02,\n",
       "        5.1319e-06, 3.9162e-07, 6.6421e-09, 8.1745e-04, 6.2547e-04, 2.8928e-05,\n",
       "        4.3990e-06, 6.1138e-05, 1.2171e-05, 2.9681e-02, 1.1179e-01, 1.2083e-06,\n",
       "        6.4868e-07, 3.3909e-06, 4.2358e-09])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = attn.data[0,:,0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File imported (4102 reviews)\n"
     ]
    }
   ],
   "source": [
    "# Import (created) data\n",
    "import json\n",
    "\n",
    "with open('yelp_reviews_part1.json') as json_file:\n",
    "    reviews = json.load(json_file)\n",
    "\n",
    "print(\"File imported ({} reviews)\".format(len(reviews)))\n",
    "\n",
    "keys = list(reviews.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Really good place with simple decor, amazing food and great hospitality.\\nVery impressed with the lunch portion. Although service took little extra time but I have no complaints since they are quite new in business. The green curry chicken was good and to the right spice balance I asked for. I will definitely recommend this place to others.'"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = reviews[keys[6]]['text']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = df['word'].tolist()\n",
    "\n",
    "words = re.findall(r\"[\\w']+\", text)\n",
    "words = [w.lower().replace(\"'\", \" \") for w in words if w in wordsList]\n",
    "tmp = df[df['word'].isin(words)]\n",
    "vectors = [tmp[tmp['word'] == w].iloc[0,2:].tolist() for w in words]\n",
    "\n",
    "x = torch.tensor(vectors).view(1, -1, 128)\n",
    "encoder_outputs = encoder(x)\n",
    "output, attn = classifier(encoder_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\">{}</span>'.format(html_color, word)\n",
    "\n",
    "def mk_html(sentence, attns):\n",
    "    html = \"\"\n",
    "    for word, attn in zip(sentence, attns):\n",
    "        html += ' ' + highlight(\n",
    "            word,\n",
    "            attn\n",
    "        )\n",
    "    return html + \"<br><br>\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 4\n",
    "\n",
    "text = reviews[keys[k]]['text']\n",
    "star = reviews[keys[k]]['stars']\n",
    "\n",
    "wordsList = df['word'].tolist()\n",
    "\n",
    "words = re.findall(r\"[\\w']+\", text)\n",
    "words = [w.lower().replace(\"'\", \" \") for w in words if w in wordsList]\n",
    "tmp = df[df['word'].isin(words)]\n",
    "vectors = [tmp[tmp['word'] == w].iloc[0,2:].tolist() for w in words]\n",
    "\n",
    "x = torch.tensor(vectors).view(1, -1, 128)\n",
    "encoder_outputs = encoder(x)\n",
    "output, attn = classifier(encoder_outputs)\n",
    "\n",
    "starpred = min(max(1, round(float(output))), 5)\n",
    "\n",
    "a = attn.data[0,:,0]\n",
    "\n",
    "\n",
    "words = re.findall(r\"[\\w']+\", text)\n",
    "words = [w.lower().replace(\"'\", \" \") for w in words if w in wordsList]\n",
    "\n",
    "wordsLst = []\n",
    "wordsAttn = []\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "w =  words[k]\n",
    "l = len(w)\n",
    "while i < len(text):\n",
    "    wt = text[i:(i+l)]\n",
    "    if wt.lower().replace(\"'\", \" \").replace(\"\\n\", \"\") == w : \n",
    "        wordsLst.append(text[j:i])\n",
    "        wordsAttn.append(0)\n",
    "        wordsLst.append(wt)\n",
    "        wordsAttn.append(float(a[k]))\n",
    "        i = i+l\n",
    "        j = i\n",
    "        k += 1\n",
    "        try : \n",
    "            w =  words[k]\n",
    "            l = len(w)\n",
    "        except : break\n",
    "    else :\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"attn.html\", \"w\")\n",
    "f.write( '\\t'.join([str(int(star)), str(starpred), mk_html(wordsLst, wordsAttn)]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dismal, lukewarm, defrosted-tasting \"TexMex\" glop;\\n\\nMumbly, unengaged waiter;\\n\\nClueless manager, who seeing us with barely nibbled entrees\\non plates shoved forward for pickup, thanked us\\nperfunctorily for our patronage;\\n\\nWe\\'re from the Texas Hill Country;\\ndown there, we jail critters \\nwho serve up grub this bad,\\nfor their own protection.\\n\\nNever, never, NEVER again\\n(Back to Yard House for real food)'"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Really good place with simple decor, amazing food and great hospitality.\\nVery impressed with the lunch portion. Although service took little extra time but I have no complaints since they are quite new in business. The green curry chicken was good and to the right spice balance I asked for. I will definitely recommend this place to others.'"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'place'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Really ': 0,\n",
       " 'good': 0.008519185706973076,\n",
       " ' ': 0,\n",
       " 'place': 8.057260743044026e-07,\n",
       " 'with': 0.00010041088535217568,\n",
       " 'simple': 1.8584192730486393e-05,\n",
       " 'decor': 0.043511517345905304,\n",
       " ', ': 0,\n",
       " 'amazing': 0.2592686414718628,\n",
       " 'food': 0.002137534786015749,\n",
       " 'and': 3.22355299431365e-06,\n",
       " 'great': 0.31096503138542175,\n",
       " 'hospitality': 0.003158975625410676,\n",
       " '.\\nVery ': 0,\n",
       " 'impressed': 0.0008085811859928071,\n",
       " 'the': 1.8984486871431727e-07,\n",
       " 'lunch': 0.013776425272226334,\n",
       " 'portion': 0.007655754219740629,\n",
       " '. Although ': 0,\n",
       " 'service': 0.00029548941529355943,\n",
       " 'took': 1.7773362515072222e-06,\n",
       " 'little': 4.475287198602018e-07,\n",
       " 'extra': 3.3218679163837805e-05,\n",
       " 'time': 1.5490697478526272e-05,\n",
       " 'but': 7.776482561894227e-06,\n",
       " ' I ': 0,\n",
       " 'have': 0.0008112172945402563,\n",
       " 'no': 0.002674650400876999,\n",
       " 'complaints': 2.2990123397903517e-05,\n",
       " 'since': 0.0007223040447570384,\n",
       " 'they': 0.008232345804572105,\n",
       " 'are': 0.0005870381137356162,\n",
       " 'quite': 0.019895952194929123,\n",
       " 'new': 0.02636522799730301,\n",
       " 'in': 0.00025865714997053146,\n",
       " 'business': 2.9126054869266227e-05,\n",
       " '. The ': 0,\n",
       " 'green': 0.005016383249312639,\n",
       " 'curry': 0.00021648868278134614,\n",
       " 'chicken': 0.0005873827612958848,\n",
       " 'was': 2.086547829094343e-05,\n",
       " 'to': 8.110954041740115e-08,\n",
       " 'right': 1.383965809509391e-05,\n",
       " 'spice': 2.0088928067707457e-06,\n",
       " 'balance': 8.303700451506302e-05,\n",
       " 'asked': 4.324750989326276e-05,\n",
       " 'for': 5.393641913542524e-05,\n",
       " '. I ': 0,\n",
       " 'will': 4.496339170145802e-05,\n",
       " 'definitely': 0.00044800853356719017,\n",
       " 'recommend': 0.10949685424566269,\n",
       " 'this': 0.00011002142127836123,\n",
       " 'others': 1.6913493254833156e-06}"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
